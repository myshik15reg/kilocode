import type { ModelInfo } from "../model.js"

export type VscodeLlmModelId = keyof typeof vscodeLlmModels

export const vscodeLlmDefaultModelId: VscodeLlmModelId = "claude-4-sonnet"

export const vscodeLlmModels = {
	"gpt-3.5-turbo": {
		contextWindow: 16384,
		maxTokens: 4096,
		supportsImages: false,
		supportsPromptCache: false,
		inputPrice: 0,
		outputPrice: 0,
		family: "gpt-3.5-turbo",
		version: "gpt-3.5-turbo-0613",
		name: "GPT 3.5 Turbo",
		supportsToolCalling: true,
		maxInputTokens: 12288,
	},
	"gpt-4o-mini": {
		contextWindow: 128000,
		maxTokens: 4096,
		supportsImages: true,
		supportsPromptCache: false,
		inputPrice: 0,
		outputPrice: 0,
		family: "gpt-4o-mini",
		version: "gpt-4o-mini-2024-07-18",
		name: "GPT-4o mini",
		supportsToolCalling: true,
		maxInputTokens: 12288,
	},
	"gpt-4": {
		contextWindow: 32768,
		maxTokens: 4096,
		supportsImages: false,
		supportsPromptCache: false,
		inputPrice: 0,
		outputPrice: 0,
		family: "gpt-4",
		version: "gpt-4-0613",
		name: "GPT 4",
		supportsToolCalling: true,
		maxInputTokens: 32768,
	},
	"gpt-4-0125-preview": {
		contextWindow: 128000,
		maxTokens: 4096,
		supportsImages: false,
		supportsPromptCache: false,
		inputPrice: 0,
		outputPrice: 0,
		family: "gpt-4-turbo",
		version: "gpt-4-0125-preview",
		name: "GPT 4 Turbo",
		supportsToolCalling: true,
		maxInputTokens: 64000,
	},
	"gpt-4o": {
		contextWindow: 128000,
		maxTokens: 16384,
		supportsImages: true,
		supportsPromptCache: false,
		inputPrice: 0,
		outputPrice: 0,
		family: "gpt-4o",
		version: "gpt-4o-2024-11-20",
		name: "GPT-4o",
		supportsToolCalling: true,
		maxInputTokens: 64000,
	},
	o1: {
		contextWindow: 19827,
		supportsImages: false,
		supportsPromptCache: false,
		inputPrice: 0,
		outputPrice: 0,
		family: "o1-ga",
		version: "o1-2024-12-17",
		name: "o1 (Preview)",
		supportsToolCalling: true,
		maxInputTokens: 19827,
	},
	"o3-mini": {
		contextWindow: 200000,
		maxTokens: 100000,
		supportsImages: false,
		supportsPromptCache: false,
		inputPrice: 0,
		outputPrice: 0,
		family: "o3-mini",
		version: "o3-mini-2025-01-31",
		name: "o3-mini",
		supportsToolCalling: true,
		maxInputTokens: 64000,
	},
	"claude-3.5-sonnet": {
		contextWindow: 90000,
		maxTokens: 8192,
		supportsImages: true,
		supportsPromptCache: false,
		inputPrice: 0,
		outputPrice: 0,
		family: "claude-3.5-sonnet",
		version: "claude-3.5-sonnet",
		name: "Claude 3.5 Sonnet",
		supportsToolCalling: true,
		maxInputTokens: 90000,
	},
	"claude-4-sonnet": {
		contextWindow: 216000,
		maxTokens: 16000,
		supportsImages: true,
		supportsPromptCache: false,
		inputPrice: 0,
		outputPrice: 0,
		family: "claude-sonnet-4",
		version: "claude-sonnet-4",
		name: "Claude Sonnet 4",
		supportsToolCalling: true,
		maxInputTokens: 128000,
	},
	"gemini-2.0-flash-001": {
		contextWindow: 1000000,
		maxTokens: 8192,
		supportsImages: true,
		supportsPromptCache: false,
		inputPrice: 0,
		outputPrice: 0,
		family: "gemini-2.0-flash",
		version: "gemini-2.0-flash-001",
		name: "Gemini 2.0 Flash",
		supportsToolCalling: false,
		maxInputTokens: 128000,
	},
	"gemini-2.5-pro": {
		contextWindow: 128000,
		maxTokens: 64000,
		supportsImages: true,
		supportsPromptCache: false,
		inputPrice: 0,
		outputPrice: 0,
		family: "gemini-2.5-pro",
		version: "gemini-2.5-pro",
		name: "Gemini 2.5 Pro",
		supportsToolCalling: true,
		maxInputTokens: 128000,
	},
	"o4-mini": {
		contextWindow: 200000,
		maxTokens: 100000,
		supportsImages: true,
		supportsPromptCache: false,
		inputPrice: 0,
		outputPrice: 0,
		family: "o4-mini",
		version: "o4-mini-2025-04-16",
		name: "o4-mini (Preview)",
		supportsToolCalling: true,
		maxInputTokens: 128000,
	},
	"gpt-4.1": {
		contextWindow: 128000,
		maxTokens: 16384,
		supportsImages: true,
		supportsPromptCache: false,
		inputPrice: 0,
		outputPrice: 0,
		family: "gpt-4.1",
		version: "gpt-4.1-2025-04-14",
		name: "GPT-4.1",
		supportsToolCalling: true,
		maxInputTokens: 128000,
	},
	"gpt-5-mini": {
		contextWindow: 264000,
		maxTokens: 127805,
		supportsImages: true,
		supportsPromptCache: false,
		inputPrice: 0,
		outputPrice: 0,
		family: "gpt-5-mini",
		version: "gpt-5-mini",
		name: "GPT-5 mini",
		supportsToolCalling: true,
		maxInputTokens: 128000,
	},
	"gpt-5": {
		contextWindow: 264000,
		maxTokens: 64000,
		supportsImages: true,
		supportsPromptCache: false,
		inputPrice: 0,
		outputPrice: 0,
		family: "gpt-5",
		version: "gpt-5",
		name: "GPT-5",
		supportsToolCalling: true,
		maxInputTokens: 128000,
	},
} as const satisfies Record<
	string,
	ModelInfo & {
		family: string
		version: string
		name: string
		supportsToolCalling: boolean
		maxInputTokens: number
	}
>
